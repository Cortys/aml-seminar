# Paper Outline

1. Introduction
2. Hyperparameter optimization
	1. Fabolas (grid search subsampling, general purpose)
	2. early termination (NN)
3. Parameter optimization
	1. BLB (bootstrapping, general purpose)
	2. sample size selection (grad desc)
	3. OSMAC (subsampling for log reg)
	4. local learning (SVM + K means)
4. Conclusion

Subsection ordering TBD.
